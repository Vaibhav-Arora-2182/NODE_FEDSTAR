{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d497a-ee79-48be-afa6-27aea8ff58f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T03:17:17.367343Z",
     "iopub.status.busy": "2023-04-25T03:17:17.366761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from -r FedStar/requirements.txt (line 1)) (1.23.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from -r FedStar/requirements.txt (line 2)) (1.4.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from -r FedStar/requirements.txt (line 3)) (1.1.1)\n",
      "Collecting dtaidistance\n",
      "  Downloading dtaidistance-2.3.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from -r FedStar/requirements.txt (line 5)) (1.12.0+cu116)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from -r FedStar/requirements.txt (line 6)) (0.13.0+cu116)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (from -r FedStar/requirements.txt (line 7)) (0.12.0+cu116)\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.1.1.tar.gz (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch-sparse\n",
      "  Downloading torch_sparse-0.6.17.tar.gz (209 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    }
   ],
   "source": [
    "!pip install -r FedStar/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d68cc98-d28b-4ffe-8afe-63360f89b690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T06:11:23.615510Z",
     "iopub.status.busy": "2023-04-25T06:11:23.615071Z",
     "iopub.status.idle": "2023-04-25T06:14:08.438784Z",
     "shell.execute_reply": "2023-04-25T06:14:08.437396Z",
     "shell.execute_reply.started": "2023-04-25T06:11:23.615461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-25 06:11:24--  http://vision.cs.aston.ac.uk/datasets/UCID/data/ucid.v2.tar.gz\n",
      "Resolving vision.cs.aston.ac.uk (vision.cs.aston.ac.uk)... 134.151.37.9\n",
      "Connecting to vision.cs.aston.ac.uk (vision.cs.aston.ac.uk)|134.151.37.9|:80... failed: Connection timed out.\n",
      "Retrying.\n",
      "\n",
      "--2023-04-25 06:13:35--  (try: 2)  http://vision.cs.aston.ac.uk/datasets/UCID/data/ucid.v2.tar.gz\n",
      "Connecting to vision.cs.aston.ac.uk (vision.cs.aston.ac.uk)|134.151.37.9|:80... ^C\n"
     ]
    }
   ],
   "source": [
    "!wget http://vision.cs.aston.ac.uk/datasets/UCID/data/ucid.v2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b18fbe5-9cbc-434a-866e-813962050d36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T16:31:46.878248Z",
     "iopub.status.busy": "2023-04-24T16:31:46.877514Z",
     "iopub.status.idle": "2023-04-24T16:31:49.178798Z",
     "shell.execute_reply": "2023-04-24T16:31:49.177903Z",
     "shell.execute_reply.started": "2023-04-24T16:31:46.878175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#generic\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import argparse\n",
    "import random\n",
    "import copy\n",
    "from random import choices\n",
    "import pickle\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GINConv, global_add_pool, SAGEConv\n",
    "from torch_geometric.transforms import OneHotDegree\n",
    "from torch_geometric.utils import to_networkx, degree, to_dense_adj, to_scipy_sparse_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse as sp\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset, Batch\n",
    "from torch_geometric.utils import to_networkx, subgraph\n",
    "import torch_geometric.utils as utils\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "\n",
    "#utility\n",
    "import networkx as nx\n",
    "from dtaidistance import dtw\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymetis\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import tqdm\n",
    "\n",
    "num_clients = 3\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "alg = 'fedstar'\n",
    "num_rounds = 20\n",
    "local_epoch = 10\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "nlayer = 3 # number of GINConv layers\n",
    "hidden = 64\n",
    "dropout = 0.5\n",
    "batch_size = 128  # not used\n",
    "seed = 69\n",
    "datapath = '.Data'\n",
    "outbase = 'outputs'\n",
    "data_group = 'arxiv'\n",
    "n_rw = 16\n",
    "n_dg = 16\n",
    "n_ones = 16\n",
    "type_init = 'rw_dg' #options are rw, dg and rw_dg\n",
    "print(device)\n",
    "seed_dataSplit = 123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de33bd3d-c119-42aa-b998-6f7c61d29a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T16:31:49.180562Z",
     "iopub.status.busy": "2023-04-24T16:31:49.180182Z",
     "iopub.status.idle": "2023-04-24T16:31:49.192922Z",
     "shell.execute_reply": "2023-04-24T16:31:49.192241Z",
     "shell.execute_reply.started": "2023-04-24T16:31:49.180541Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_numGraphLabels(g):\n",
    "    s = set(g.y.flatten().tolist())\n",
    "    return len(s)\n",
    "\n",
    "def init_structure_encoding(  g, type_init = 'rw_dg'):\n",
    "\n",
    "    if type_init == 'rw':\n",
    "        # Geometric diffusion features with Random Walk\n",
    "        A = to_scipy_sparse_matrix(g.edge_index, num_nodes=g.num_nodes)\n",
    "        D = (degree(g.edge_index[0], num_nodes=g.num_nodes) ** -1.0).numpy()\n",
    "\n",
    "        Dinv=sp.diags(D)\n",
    "        RW=A*Dinv\n",
    "        M=RW\n",
    "\n",
    "        SE_rw=[torch.from_numpy(M.diagonal()).float()]\n",
    "        M_power=M\n",
    "        for _ in range(n_rw-1):\n",
    "            M_power=M_power*M\n",
    "            SE_rw.append(torch.from_numpy(M_power.diagonal()).float())\n",
    "        SE_rw=torch.stack(SE_rw,dim=-1)\n",
    "\n",
    "        g['stc_enc'] = SE_rw\n",
    "\n",
    "    elif type_init == 'dg':\n",
    "        # PE_degree\n",
    "        g_dg = (degree(g.edge_index[0], num_nodes=g.num_nodes)).numpy().clip(1, n_dg)\n",
    "        SE_dg = torch.zeros([g.num_QCnodes, n_dg])\n",
    "        for i in range(len(g_dg)):\n",
    "            SE_dg[i,int(g_dg[i]-1)] = 1\n",
    "\n",
    "        g['stc_enc'] = SE_dg\n",
    "\n",
    "    elif type_init == 'rw_dg':\n",
    "        # SE_rw\n",
    "        A = to_scipy_sparse_matrix(g.edge_index, num_nodes=g.num_nodes)\n",
    "        D = (degree(g.edge_index[0], num_nodes=g.num_nodes) ** -1.0).numpy()\n",
    "\n",
    "        Dinv=sp.diags(D)\n",
    "        RW=A*Dinv\n",
    "        M=RW\n",
    "\n",
    "        SE=[torch.from_numpy(M.diagonal()).float()]\n",
    "        M_power=M\n",
    "        for _ in range(n_rw-1):\n",
    "            M_power=M_power*M\n",
    "            SE.append(torch.from_numpy(M_power.diagonal()).float())\n",
    "        SE_rw=torch.stack(SE,dim=-1)\n",
    "\n",
    "        # PE_degree\n",
    "        g_dg = (degree(g.edge_index[0], num_nodes=g.num_nodes)).numpy().clip(1, n_dg)\n",
    "        SE_dg = torch.zeros([g.num_nodes, n_dg])\n",
    "        for i in range(len(g_dg)):\n",
    "            SE_dg[i,int(g_dg[i]-1)] = 1\n",
    "\n",
    "        g['stc_enc'] = torch.cat([SE_rw, SE_dg], dim=1)\n",
    "\n",
    "    return g\n",
    "\n",
    "def get_stats(df, ds, graph_train, graph_val=None, graph_test=None):\n",
    "    from collections import Counter\n",
    "    labels_train = graph_train.y.flatten().tolist()\n",
    "    df.loc[ds, '#Nodes_train'] = graph_train.num_nodes\n",
    "    df.loc[ds, '#Edges_train'] = graph_train.num_edges\n",
    "    df.loc[ds, 'Avg_degree_train'] = graph_train.num_edges/graph_train.num_nodes\n",
    "    df.loc[ds, '#Labels_train'] = len(set(labels_train))\n",
    "    df.loc[ds, 'Class_dist_train'] = str(dict(Counter(labels_train)))\n",
    "    \n",
    "    if graph_test:\n",
    "        labels_test = graph_test.y.flatten().tolist()\n",
    "        df.loc[ds, '#Nodes_test'] = graph_test.num_nodes\n",
    "        df.loc[ds, '#Edges_test'] = graph_test.num_edges\n",
    "        df.loc[ds, 'Avg_degree_test'] = graph_test.num_edges/graph_test.num_nodes\n",
    "        df.loc[ds, '#Labels_test'] = len(set(labels_test))\n",
    "        df.loc[ds, 'Class_dist_test'] = str(dict(Counter(labels_test)))\n",
    "        \n",
    "    if graph_val:\n",
    "        labels_val = graph_val.y.flatten().tolist()\n",
    "        df.loc[ds, '#Nodes_val'] = graph_val.num_nodes\n",
    "        df.loc[ds, '#Edges_val'] = graph_val.num_edges\n",
    "        df.loc[ds, 'Avg_degree_val'] = graph_val.num_edges/graph_val.num_nodes\n",
    "        df.loc[ds, '#Labels_val'] = len(set(labels_val))\n",
    "        df.loc[ds, 'Class_dist_val'] = str(dict(Counter(labels_val)))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390e2f5f-8429-456e-a151-a692c2a31890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T16:31:49.193776Z",
     "iopub.status.busy": "2023-04-24T16:31:49.193593Z",
     "iopub.status.idle": "2023-04-24T16:31:49.591736Z",
     "shell.execute_reply": "2023-04-24T16:31:49.591039Z",
     "shell.execute_reply.started": "2023-04-24T16:31:49.193758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1], stc_enc=[169343, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('graph_struc_pickle', 'rb')\n",
    "graph = pickle.load(file)\n",
    "file.close()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca48f65-fe54-46b7-b439-76b0a6731c2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T16:31:50.974661Z",
     "iopub.status.busy": "2023-04-24T16:31:50.974045Z",
     "iopub.status.idle": "2023-04-24T16:31:52.529505Z",
     "shell.execute_reply": "2023-04-24T16:31:52.528812Z",
     "shell.execute_reply.started": "2023-04-24T16:31:50.974637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 40], stc_enc=[169343, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GIN_dc(torch.nn.Module):\n",
    "    def __init__(self, nfeat, n_se, nhid, nclass, nlayer, dropout):\n",
    "        super(GIN_dc, self).__init__()\n",
    "        self.num_layers = nlayer\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.pre = torch.nn.Sequential(torch.nn.Linear(nfeat, nhid))\n",
    "\n",
    "        self.embedding_s = torch.nn.Linear(n_se, nhid)\n",
    "\n",
    "        self.graph_convs = torch.nn.ModuleList()\n",
    "        self.nn1 = torch.nn.Sequential(torch.nn.Linear(nhid + nhid, nhid), torch.nn.ReLU(), torch.nn.Linear(nhid, nhid))\n",
    "        self.graph_convs.append(GINConv(self.nn1))\n",
    "        self.graph_convs_s_gcn = torch.nn.ModuleList()\n",
    "        self.graph_convs_s_gcn.append(GCNConv(nhid, nhid))\n",
    "\n",
    "        for l in range(nlayer - 1):\n",
    "            self.nnk = torch.nn.Sequential(torch.nn.Linear(nhid + nhid, nhid), torch.nn.ReLU(), torch.nn.Linear(nhid, nhid))\n",
    "            self.graph_convs.append(GINConv(self.nnk))\n",
    "            self.graph_convs_s_gcn.append(GCNConv(nhid, nhid))\n",
    "\n",
    "        self.Whp = torch.nn.Linear(nhid + nhid, nhid)\n",
    "        self.post = torch.nn.Sequential(torch.nn.Linear(nhid, nhid), torch.nn.ReLU())\n",
    "        self.readout = torch.nn.Sequential(torch.nn.Linear(nhid, nclass))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, s = data.x, data.edge_index, data.stc_enc\n",
    "        x = self.pre(x)\n",
    "        s = self.embedding_s(s)\n",
    "        for i in range(len(self.graph_convs)):\n",
    "            x = torch.cat((x, s), -1)\n",
    "            x = self.graph_convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            s = self.graph_convs_s_gcn[i](s, edge_index)\n",
    "            s = torch.tanh(s)\n",
    "        x = self.Whp(torch.cat((x, s), -1))\n",
    "        x = self.post(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.readout(x)\n",
    "        # print(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        # print(x)\n",
    "        return x.float()\n",
    "    def loss(self, pred, label):\n",
    "        # print(pred, label)\n",
    "        return F.cross_entropy(pred, label)\n",
    "        # return F.nll_loss(pred, label)\n",
    "data = copy.deepcopy(graph)\n",
    "num_classes = get_numGraphLabels(data)\n",
    "n_se = n_rw+n_dg\n",
    "data.y = one_hot(data.y).squeeze(dim=1).float()\n",
    "model = GIN_dc(nfeat=data.num_node_features, n_se=n_se, nhid=64, nclass=num_classes, nlayer=3, dropout=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3f43afa-635f-4e76-840b-a29a445d0ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T06:08:33.528769Z",
     "iopub.status.busy": "2023-04-24T06:08:33.527903Z",
     "iopub.status.idle": "2023-04-24T06:08:33.539509Z",
     "shell.execute_reply": "2023-04-24T06:08:33.538333Z",
     "shell.execute_reply.started": "2023-04-24T06:08:33.528732Z"
    }
   },
   "outputs": [],
   "source": [
    "per = torch.randperm(data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89eeb891-3909-4d28-9cda-07c56b53d64f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T06:44:54.432301Z",
     "iopub.status.busy": "2023-04-24T06:44:54.431432Z",
     "iopub.status.idle": "2023-04-24T07:13:41.678674Z",
     "shell.execute_reply": "2023-04-24T07:13:41.677262Z",
     "shell.execute_reply.started": "2023-04-24T06:44:54.432256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 326294302.67658997 4273 2.5232811512728603\n",
      "epoch=1 326372319.4695916 4350 2.5687509964982316\n",
      "epoch=2 326097088.06268835 4324 2.553397542266288\n",
      "epoch=3 326572505.798996 4365 2.577608758555122\n",
      "epoch=4 326675604.1150408 4244 2.506156144629539\n",
      "epoch=5 326140412.3133693 4409 2.603591527255334\n",
      "epoch=6 326823382.5893841 4263 2.5173759765682666\n",
      "epoch=7 326278767.6821778 4327 2.555169094677666\n",
      "epoch=8 326818438.9265218 4290 2.5333199482706696\n",
      "epoch=9 326441913.9854653 4252 2.5108802843932136\n",
      "epoch=10 326505077.26677394 4279 2.5268242560956167\n",
      "epoch=11 326703572.72160435 4368 2.5793803109665\n",
      "epoch=12 326655642.3296597 4354 2.571113066380069\n",
      "epoch=13 326309872.6503229 4226 2.4955268301612703\n",
      "epoch=14 326368298.9786763 4272 2.522690633802401\n",
      "epoch=15 326572511.3947983 4354 2.571113066380069\n",
      "epoch=16 326328794.6280587 4295 2.5362725356229663\n",
      "epoch=17 326508996.8394308 4361 2.5752466886732845\n",
      "epoch=18 326868802.4372189 4307 2.543358745268479\n",
      "epoch=19 326404487.56867194 4289 2.5327294308002104\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "model = GIN_dc(nfeat=data.num_node_features, n_se=n_se, nhid=64, nclass=num_classes, nlayer=3, dropout=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "batch_size = 1024\n",
    "data.to(device)\n",
    "start = 0\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "for epoch in range(20):\n",
    "    acc_sum = 0\n",
    "    total_loss = 0\n",
    "    all = torch.randperm(data.num_nodes)\n",
    "    for batch_num in range(data.num_nodes//batch_size):\n",
    "    # batch = random.choices(all, k=len(all)//20)\n",
    "        model.train()\n",
    "        model.to(data.x.device)\n",
    "        data.to(device)\n",
    "        # print(f'epoch={epoch}')\n",
    "        loss = torch.tensor([0.0], device='cuda:0')\n",
    "    # loss.to(device)\n",
    "    # print(loss.device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "    # break\n",
    "#     print(out.shape, data.y.shape)\n",
    "#     loss = model.loss(out, data.y)\n",
    "        out.to(device)\n",
    "    # for i in range(out.shape[0]): \n",
    "        batch = per[batch_size*batch_num:batch_size*(batch_num+1)]\n",
    "        for i in batch :\n",
    "        # i_tensor = torch.tensor([i], dtype=torch.long, device=out.device)\n",
    "            loss += model.loss(out[i], data.y[i])\n",
    "            total_loss += loss.item()\n",
    "        # loss += model.loss(out[i], data.y[i])\n",
    "# Convert one-hot encoded labels to class indices\n",
    "# Calculate number of correct predictions\n",
    "        acc_sum = out.max(dim=1)[1].eq(data.y.max(dim=1)[1]).sum().item()\n",
    "        # acc_sum += acc\n",
    "        # if start == 0 : print(f'epoch={epoch}', total_loss, acc_sum, acc_sum*100/data.num_nodes)\n",
    "        # start = 1\n",
    "        # print(loss.item(), acc_sum, acc_sum*100/data.num_nodes)\n",
    "    # break\n",
    "        loss.backward()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "    print(f'epoch={epoch}', total_loss, acc_sum, acc_sum*100/data.num_nodes)\n",
    "    # optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d00ffee-165b-4290-84ac-bea9d7ad1b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T16:45:49.034926Z",
     "iopub.status.busy": "2023-04-24T16:45:49.034178Z",
     "iopub.status.idle": "2023-04-24T17:37:27.691957Z",
     "shell.execute_reply": "2023-04-24T17:37:27.686342Z",
     "shell.execute_reply.started": "2023-04-24T16:45:49.034900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0 651575.9375 2490 1.4703885014438152\n",
      "epoch-1 6497465856.0 20797 12.280991833143384\n",
      "epoch-2 280105216.0 23410 13.8240139834537\n",
      "epoch-3 21737978.0 12795 7.555671034527556\n",
      "epoch-4 6683801088.0 9634 5.6890453104055085\n",
      "epoch-5 26866046.0 12121 7.157662259437945\n",
      "epoch-6 11571762.0 9978 5.89218332024353\n",
      "epoch-7 7295755.0 12111 7.151757084733352\n",
      "epoch-8 1479485.125 9346 5.518976278913212\n",
      "epoch-9 896559.8125 5813 3.43267805578028\n",
      "epoch-10 621848.3125 6240 3.6848290156664283\n",
      "epoch-11 656478.625 21383 12.627035070832571\n",
      "epoch-12 597703.9375 21401 12.63766438530084\n",
      "epoch-13 592652.5625 21406 12.640616972653136\n",
      "epoch-14 3814739.25 21379 12.624673000950732\n",
      "epoch-15 761229.125 21407 12.641207490123595\n",
      "epoch-16 575462.9375 21407 12.641207490123595\n",
      "epoch-17 570312.8125 21405 12.640026455182676\n",
      "epoch-18 564959.4375 21405 12.640026455182676\n",
      "epoch-19 560239.3125 21405 12.640026455182676\n",
      "epoch-20 555848.9375 21404 12.639435937712218\n",
      "epoch-21 550875.9375 21408 12.641798007594055\n",
      "epoch-22 546820.625 21404 12.639435937712218\n",
      "epoch-23 542333.125 21406 12.640616972653136\n",
      "epoch-24 539014.625 21406 12.640616972653136\n",
      "epoch-25 535339.0625 21406 12.640616972653136\n",
      "epoch-26 531879.8125 21406 12.640616972653136\n",
      "epoch-27 528653.625 21406 12.640616972653136\n",
      "epoch-28 526598.0625 21406 12.640616972653136\n",
      "epoch-29 524336.0625 21406 12.640616972653136\n",
      "epoch-30 547053.25 21403 12.638845420241758\n",
      "epoch-31 520158.0 21406 12.640616972653136\n",
      "epoch-32 517968.21875 21406 12.640616972653136\n",
      "epoch-33 516325.40625 21406 12.640616972653136\n",
      "epoch-34 515085.0 21406 12.640616972653136\n",
      "epoch-35 514160.1875 21406 12.640616972653136\n",
      "epoch-36 512922.53125 22187 13.1018111170819\n",
      "epoch-37 512223.5625 22187 13.1018111170819\n",
      "epoch-38 511702.125 22187 13.1018111170819\n",
      "epoch-39 510663.5 22187 13.1018111170819\n",
      "epoch-40 510028.40625 22187 13.1018111170819\n",
      "epoch-41 509552.5625 22187 13.1018111170819\n",
      "epoch-42 509285.625 22187 13.1018111170819\n",
      "epoch-43 508842.8125 22187 13.1018111170819\n",
      "epoch-44 508671.125 22187 13.1018111170819\n",
      "epoch-45 508565.875 22187 13.1018111170819\n",
      "epoch-46 508031.15625 22187 13.1018111170819\n",
      "epoch-47 508079.09375 27321 16.133527810420272\n",
      "epoch-48 507794.375 27321 16.133527810420272\n",
      "epoch-49 507720.28125 27321 16.133527810420272\n"
     ]
    }
   ],
   "source": [
    "model = GIN_dc(nfeat=data.num_node_features, n_se=n_se, nhid=64, nclass=num_classes, nlayer=3, dropout=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    loss = torch.tensor([0.0], device='cuda:0')\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "\n",
    "    for i in range(out.shape[0]) : loss += model.loss(out[i], data.y[i])\n",
    "    acc_sum = out.max(dim=1)[1].eq(data.y.max(dim=1)[1]).sum().item()\n",
    "    print(f'epoch-{epoch}',loss.item(), acc_sum, acc_sum*100/data.num_nodes)    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1ba85d-d42e-4760-babe-85c4cd54cae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T17:37:27.743382Z",
     "iopub.status.busy": "2023-04-24T17:37:27.743017Z",
     "iopub.status.idle": "2023-04-24T18:30:18.981599Z",
     "shell.execute_reply": "2023-04-24T18:30:18.980744Z",
     "shell.execute_reply.started": "2023-04-24T17:37:27.743360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0 734984.875 3710 2.1908198154042386\n",
      "epoch-1 22825074688.0 27274 16.10577348930868\n",
      "epoch-2 469514560.0 19319 11.408207011804445\n",
      "epoch-3 595741.5625 19616 11.583590700530875\n",
      "epoch-4 1240723.25 18542 10.949374937257518\n",
      "epoch-5 6899958.0 15475 9.13825785535865\n",
      "epoch-6 594683.5 18177 10.73383606053985\n",
      "epoch-7 650151.5 18027 10.645258439970947\n",
      "epoch-8 566168.0 17766 10.491133380181052\n",
      "epoch-9 561576.875 17096 10.095486674973278\n",
      "epoch-10 556037.25 17598 10.391926445143879\n",
      "epoch-11 550756.4375 18626 10.998978404776105\n",
      "epoch-12 547767.0625 19549 11.544026030010098\n",
      "epoch-13 544715.875 20441 12.07076761365985\n",
      "epoch-14 540745.4375 21482 12.685496300408047\n",
      "epoch-15 538318.6875 21769 12.854974814429886\n",
      "epoch-16 536066.0625 21684 12.804780829440839\n",
      "epoch-17 533345.6875 21761 12.85025067466621\n",
      "epoch-18 530799.3125 21842 12.898082589773418\n",
      "epoch-19 528958.5625 21881 12.921112771121333\n",
      "epoch-20 526862.8125 21817 12.883319653011934\n",
      "epoch-21 524818.5 21923 12.945914504880626\n",
      "epoch-22 523051.8125 21683 12.80419031197038\n",
      "epoch-23 521601.875 21836 12.894539484950663\n",
      "epoch-24 520330.78125 21840 12.8969015548325\n",
      "epoch-25 518888.28125 22145 13.077009383322606\n",
      "epoch-26 517653.53125 22463 13.264793938928683\n",
      "epoch-27 516579.59375 22768 13.44490176741879\n",
      "epoch-28 515760.9375 22942 13.547651807278719\n",
      "epoch-29 514804.71875 24105 14.234423625422957\n",
      "epoch-30 513661.1875 23752 14.025970958350802\n",
      "epoch-31 512792.75 23884 14.103919264451438\n",
      "epoch-32 512372.40625 23850 14.08384167045582\n",
      "epoch-33 511844.9375 23638 13.958651966718435\n",
      "epoch-34 510934.75 24341 14.373785748451368\n",
      "epoch-35 510366.40625 24399 14.408035761738011\n",
      "epoch-36 509900.125 24299 14.348984014692075\n",
      "epoch-37 509454.875 24407 14.412759901501685\n",
      "epoch-38 509014.5 25741 15.200510207094476\n",
      "epoch-39 508728.9375 25825 15.250113674613063\n",
      "epoch-40 508442.09375 26530 15.666428491286915\n",
      "epoch-41 508240.78125 26633 15.72725179074423\n",
      "epoch-42 508060.6875 26484 15.639264687645785\n",
      "epoch-43 507910.0625 27321 16.133527810420272\n",
      "epoch-44 507705.5 27321 16.133527810420272\n",
      "epoch-45 507570.5625 27321 16.133527810420272\n",
      "epoch-46 507533.1875 27321 16.133527810420272\n",
      "epoch-47 507433.59375 27321 16.133527810420272\n",
      "epoch-48 507351.28125 27321 16.133527810420272\n",
      "epoch-49 507354.25 27321 16.133527810420272\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINConv\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, nlayer, dropout):\n",
    "        super(GIN, self).__init__()\n",
    "        self.num_layers = nlayer\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.pre = torch.nn.Sequential(torch.nn.Linear(nfeat, nhid))\n",
    "\n",
    "        self.graph_convs = torch.nn.ModuleList()\n",
    "        self.nn1 = torch.nn.Sequential(torch.nn.Linear(nhid, nhid), torch.nn.ReLU(), torch.nn.Linear(nhid, nhid))\n",
    "        self.graph_convs.append(GINConv(self.nn1))\n",
    "        for l in range(nlayer - 1):\n",
    "            self.nnk = torch.nn.Sequential(torch.nn.Linear(nhid, nhid), torch.nn.ReLU(), torch.nn.Linear(nhid, nhid))\n",
    "            self.graph_convs.append(GINConv(self.nnk))\n",
    "\n",
    "        self.post = torch.nn.Sequential(torch.nn.Linear(nhid, nhid), torch.nn.ReLU())\n",
    "        self.readout = torch.nn.Sequential(torch.nn.Linear(nhid, nclass))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.pre(x)\n",
    "        for i in range(len(self.graph_convs)):\n",
    "            x = self.graph_convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "        # x = global_add_pool(x, batch)\n",
    "        x = self.post(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.readout(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.cross_entropy(pred, label)\n",
    "    \n",
    "model = GIN( nfeat = 128, nhid = 64, nclass = 40, nlayer = 3, dropout = 0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    loss = torch.tensor([0.0], device='cuda:0')\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "\n",
    "    for i in range(out.shape[0]) : loss += model.loss(out[i], data.y[i])\n",
    "    acc_sum = out.max(dim=1)[1].eq(data.y.max(dim=1)[1]).sum().item()\n",
    "    print(f'epoch-{epoch}',loss.item(), acc_sum, acc_sum*100/data.num_nodes)    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec68cb-e7b9-42d8-94fe-474d713df774",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-24T10:52:10.407324Z",
     "iopub.status.idle": "2023-04-24T10:52:10.407717Z",
     "shell.execute_reply": "2023-04-24T10:52:10.407521Z",
     "shell.execute_reply.started": "2023-04-24T10:52:10.407503Z"
    }
   },
   "outputs": [],
   "source": [
    "model = GIN_dc(nfeat=data.num_node_features, n_se=n_se, nhid=64, nclass=num_classes, nlayer=2, dropout=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    loss = torch.tensor([0.0], device='cuda:0')\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "\n",
    "    for i in range(out.shape[0]) : loss += model.loss(out[i], data.y[i])\n",
    "    acc_sum = out.max(dim=1)[1].eq(data.y.max(dim=1)[1]).sum().item()\n",
    "    print(f'epoch-{epoch}',loss.item(), acc_sum, acc_sum*100/data.num_nodes)    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60a0e4a2-4359-4413-95cd-f4bcc3e797cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T10:21:15.302616Z",
     "iopub.status.busy": "2023-04-24T10:21:15.302268Z",
     "iopub.status.idle": "2023-04-24T10:21:18.774931Z",
     "shell.execute_reply": "2023-04-24T10:21:18.773868Z",
     "shell.execute_reply.started": "2023-04-24T10:21:15.302591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.64.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f576ad2-c723-4477-b0bb-217f597416cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T10:21:42.604282Z",
     "iopub.status.busy": "2023-04-24T10:21:42.603940Z",
     "iopub.status.idle": "2023-04-24T10:52:10.185645Z",
     "shell.execute_reply": "2023-04-24T10:52:10.184707Z",
     "shell.execute_reply.started": "2023-04-24T10:21:42.604258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0 638850.375 3843 2.269358638975334\n",
      "epoch-1 612070.5 13345 7.880455643280206\n",
      "epoch-2 594977.375 15323 9.048499199848827\n",
      "epoch-3 580307.25 18690 11.036771522885505\n",
      "epoch-4 567277.375 21301 12.578612638254903\n",
      "epoch-5 557120.5625 22858 13.498048339760132\n",
      "epoch-6 549456.0625 24322 14.36256591651264\n",
      "epoch-7 541887.3125 25590 15.111342069055112\n",
      "epoch-8 535173.875 26065 15.39183786752331\n",
      "epoch-9 528745.25 25779 15.222949870971933\n",
      "epoch-10 521939.78125 26617 15.717803511216879\n",
      "epoch-11 516624.9375 28308 16.71636855376366\n",
      "epoch-12 511698.5625 32522 19.204809174279422\n",
      "epoch-13 506232.03125 36700 21.671991165858643\n",
      "epoch-14 502167.65625 38365 22.655202754173484\n",
      "epoch-15 497568.0 39734 23.46362117123235\n",
      "epoch-16 494119.90625 41007 24.21534991112712\n",
      "epoch-17 491217.71875 42019 24.812953591231995\n",
      "epoch-18 487619.28125 42990 25.386346055048037\n",
      "epoch-19 484228.0 44104 26.04418251713977\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "#Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    def loss(self, pred, label):\n",
    "        # print(pred, label)\n",
    "        return F.cross_entropy(pred, label)\n",
    "    \n",
    "model = GCN(data.num_features, 16, 40).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "data.to(device)\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    loss = torch.tensor([0.0], device='cuda:0')\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "\n",
    "    for i in range(out.shape[0]) : \n",
    "        loss += model.loss(out[i], data.y[i])\n",
    "    acc_sum = out.max(dim=1)[1].eq(data.y.max(dim=1)[1]).sum().item()\n",
    "    print(f'epoch-{epoch+1}',loss.item(), acc_sum, acc_sum*100/data.num_nodes)    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b18d7406-a82d-40fd-b8a5-1832d452f742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T10:52:23.816967Z",
     "iopub.status.busy": "2023-04-24T10:52:23.816551Z",
     "iopub.status.idle": "2023-04-24T10:52:23.828009Z",
     "shell.execute_reply": "2023-04-24T10:52:23.827122Z",
     "shell.execute_reply.started": "2023-04-24T10:52:23.816926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Expected input format of Evaluator for ogbn-arxiv\n",
      "{'y_true': y_true, 'y_pred': y_pred}\n",
      "- y_true: numpy ndarray or torch tensor of shape (num_nodes num_tasks)\n",
      "- y_pred: numpy ndarray or torch tensor of shape (num_nodes num_tasks)\n",
      "where y_pred stores predicted class label (integer),\n",
      "num_task is 1, and each row corresponds to one node.\n",
      "\n",
      "==== Expected output format of Evaluator for ogbn-arxiv\n",
      "{'acc': acc}\n",
      "- acc (float): Accuracy score averaged across 1 task(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import Evaluator\n",
    "\n",
    "evaluator = Evaluator(name = 'ogbn-arxiv')\n",
    "print(evaluator.expected_input_format) \n",
    "print(evaluator.expected_output_format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69576960-2f5b-40be-8bc8-62f91894417f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T10:56:20.187761Z",
     "iopub.status.busy": "2023-04-24T10:56:20.187426Z",
     "iopub.status.idle": "2023-04-24T10:56:20.200746Z",
     "shell.execute_reply": "2023-04-24T10:56:20.199800Z",
     "shell.execute_reply.started": "2023-04-24T10:56:20.187737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.2604418251713977}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = out.max(dim=1)[1].unsqueeze(dim=1)\n",
    "b = data.y.max(dim=1)[1].unsqueeze(dim=1)\n",
    "ans = {'y_true':b, 'y_pred': a}\n",
    "evaluator.eval(ans)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3149c9a2-013d-4943-9957-179a8524ce55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T11:12:53.475147Z",
     "iopub.status.busy": "2023-04-24T11:12:53.474608Z",
     "iopub.status.idle": "2023-04-24T11:14:00.275237Z",
     "shell.execute_reply": "2023-04-24T11:14:00.274208Z",
     "shell.execute_reply.started": "2023-04-24T11:12:53.475107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-1 4.114811897277832 8855 5.229032200917664\n",
      "epoch-6 4.114686012268066 9233 5.452247804751304\n",
      "epoch-11 4.114619731903076 8222 4.855234642116887\n",
      "epoch-16 4.11920690536499 8475 5.004635562143106\n",
      "epoch-21 4.119435787200928 9091 5.368394323946074\n",
      "epoch-26 4.112491130828857 8074 4.767838056488901\n",
      "epoch-31 4.118819713592529 8904 5.257967556970173\n",
      "epoch-36 4.113580226898193 8571 5.061325239307205\n",
      "epoch-41 4.1190900802612305 9010 5.320562408838866\n",
      "epoch-46 4.118008136749268 8139 4.8062216920687595\n",
      "epoch-51 4.12195348739624 8571 5.061325239307205\n",
      "epoch-56 4.126706600189209 9045 5.3412305203049435\n",
      "epoch-61 4.118515968322754 8033 4.743626840200068\n",
      "epoch-66 4.1193060874938965 9692 5.7232953236921515\n",
      "epoch-71 4.115555763244629 8967 5.295170157609113\n",
      "epoch-76 4.122092247009277 7488 4.4217948187997145\n",
      "epoch-81 4.113526821136475 7981 4.71291993173618\n",
      "epoch-86 4.109722137451172 8412 4.967432961504166\n",
      "epoch-91 4.119235038757324 8991 5.3093425769001374\n",
      "epoch-96 4.111802101135254 8209 4.847557915000915\n",
      "epoch-101 4.121702194213867 8382 4.949717437390385\n",
      "epoch-106 4.114114284515381 7999 4.723549246204449\n",
      "epoch-111 4.113796234130859 7996 4.72177769379307\n",
      "epoch-116 4.1210551261901855 8203 4.844014810178159\n",
      "epoch-121 4.1114349365234375 8065 4.762523399254767\n",
      "epoch-126 4.1199951171875 7800 4.6060362695830355\n",
      "epoch-131 4.1216936111450195 7984 4.714691484147559\n",
      "epoch-136 4.120323657989502 8222 4.855234642116887\n",
      "epoch-141 4.127138137817383 7861 4.642057835281057\n",
      "epoch-146 4.121650695800781 7445 4.396402567569962\n",
      "epoch-151 4.112782001495361 8662 5.115062329119007\n",
      "epoch-156 4.110257625579834 8601 5.079040763420986\n",
      "epoch-161 4.113036155700684 7984 4.714691484147559\n",
      "epoch-166 4.120687961578369 9513 5.617592696479925\n",
      "epoch-171 4.106317520141602 8196 4.839881187884943\n",
      "epoch-176 4.1151580810546875 8163 4.820394111359785\n",
      "epoch-181 4.13105583190918 8196 4.839881187884943\n",
      "epoch-186 4.1103835105896 8466 4.999320904908972\n",
      "epoch-191 4.116158485412598 6894 4.071027441346852\n",
      "epoch-196 4.118128776550293 9526 5.625269423595897\n",
      "epoch-201 4.1190185546875 8505 5.0223510862568865\n",
      "epoch-206 4.12285041809082 8767 5.17706666351724\n",
      "epoch-211 4.120109558105469 8117 4.7932303077186535\n",
      "epoch-216 4.121939659118652 8182 4.831613943298512\n",
      "epoch-221 4.1157402992248535 8660 5.113881294178088\n",
      "epoch-226 4.1190924644470215 8812 5.203639949687911\n",
      "epoch-231 4.119874000549316 7796 4.6036741997011985\n",
      "epoch-236 4.116729259490967 8768 5.1776571809876994\n",
      "epoch-241 4.109764099121094 8252 4.872950166230668\n",
      "epoch-246 4.122448444366455 9072 5.357174492007346\n",
      "epoch-251 4.129031181335449 8280 4.88948465540353\n",
      "epoch-256 4.107756614685059 8336 4.922553633749255\n",
      "epoch-261 4.117443561553955 8292 4.896570865049043\n",
      "epoch-266 4.112277507781982 7740 4.570605221355474\n",
      "epoch-271 4.128026008605957 8194 4.838700152944025\n",
      "epoch-276 4.118216514587402 7856 4.63910524792876\n",
      "epoch-281 4.117709159851074 7972 4.707605274502046\n",
      "epoch-286 4.11680269241333 8637 5.100299392357523\n",
      "epoch-291 4.116603374481201 8795 5.1936011526901025\n",
      "epoch-296 4.115289688110352 8261 4.878264823464802\n",
      "epoch-301 4.117800235748291 8333 4.920782081337876\n",
      "epoch-306 4.119259357452393 8184 4.8327949782394315\n",
      "epoch-311 4.120832920074463 8172 4.825708768593919\n",
      "epoch-316 4.119339942932129 8642 5.10325197970982\n",
      "epoch-321 4.114477157592773 9211 5.439256420401198\n",
      "epoch-326 4.114088535308838 9342 5.516614209031374\n",
      "epoch-331 4.120460033416748 8579 5.06604937907088\n",
      "epoch-336 4.130612850189209 7698 4.545803487596181\n",
      "epoch-341 4.12467098236084 9755 5.760497924331092\n",
      "epoch-346 4.122227668762207 8528 5.035932988077453\n",
      "epoch-351 4.121922492980957 8992 5.309933094370597\n",
      "epoch-356 4.122831344604492 8836 5.217812368978937\n",
      "epoch-361 4.116451740264893 7850 4.635562143106004\n",
      "epoch-366 4.115819931030273 9319 5.503032307210809\n",
      "epoch-371 4.114930152893066 8269 4.8829889632284775\n",
      "epoch-376 4.133114337921143 8235 4.862911369232859\n",
      "epoch-381 4.1234025955200195 8490 5.013493324199996\n",
      "epoch-386 4.130440711975098 8096 4.780829440839007\n",
      "epoch-391 4.110529899597168 7877 4.651506114808407\n",
      "epoch-396 4.121540069580078 7269 4.292471492769113\n",
      "epoch-401 4.124073505401611 9352 5.522519383735967\n",
      "epoch-406 4.120849609375 7590 4.482027600786569\n",
      "epoch-411 4.115063190460205 8563 5.05660109954353\n",
      "epoch-416 4.122973442077637 8146 4.810355314361975\n",
      "epoch-421 4.108874797821045 7969 4.705833722090668\n",
      "epoch-426 4.120847702026367 8398 4.9591657169177354\n",
      "epoch-431 4.125526428222656 8849 5.225489096094908\n",
      "epoch-436 4.107733249664307 8791 5.191239082808265\n",
      "epoch-441 4.120152473449707 9000 5.3146572341342715\n",
      "epoch-446 4.113949775695801 8882 5.244976172620067\n",
      "epoch-451 4.117672920227051 8229 4.859368264410103\n",
      "epoch-456 4.117433071136475 8684 5.128053713469113\n",
      "epoch-461 4.1224846839904785 9044 5.340640002834484\n",
      "epoch-466 4.121840000152588 7960 4.700519064856533\n",
      "epoch-471 4.1228861808776855 7774 4.590682815351093\n",
      "epoch-476 4.114803791046143 7981 4.71291993173618\n",
      "epoch-481 4.114247798919678 7395 4.366876694046994\n",
      "epoch-486 4.128794193267822 7788 4.598950059937523\n",
      "epoch-491 4.115890026092529 8379 4.947945884979007\n",
      "epoch-496 4.128514766693115 9111 5.380204673355261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.04508010369486781}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv',\n",
    "                                     transform=T.ToSparseTensor())\n",
    "\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric()\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x.log_softmax(dim=-1)\n",
    "data.to(device)\n",
    "num_layers=3\n",
    "hidden_channels=256\n",
    "dropout=0.5\n",
    "lr=0.01\n",
    "epochs=500\n",
    "runs=10\n",
    "model = GCN(data.num_features, hidden_channels, 40, num_layers, dropout).to(device)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)\n",
    "    loss = F.nll_loss(out, data.y.squeeze(1))\n",
    "    acc_sum = out.max(dim=1)[1].eq(data.y.max(dim=1)[1]).sum().item()\n",
    "    if epoch %5 == 0 : print(f'epoch-{epoch+1}',loss.item(), acc_sum, acc_sum*100/data.num_nodes)    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "a = out.max(dim=1)[1].unsqueeze(dim=1)\n",
    "b = data.y.max(dim=1)[1].unsqueeze(dim=1)\n",
    "ans = {'y_true':b, 'y_pred': a}\n",
    "evaluator.eval(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d2b2f6f-d131-4935-94ff-a878ab49f398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T11:14:00.276984Z",
     "iopub.status.busy": "2023-04-24T11:14:00.276729Z",
     "iopub.status.idle": "2023-04-24T11:14:00.283014Z",
     "shell.execute_reply": "2023-04-24T11:14:00.281907Z",
     "shell.execute_reply.started": "2023-04-24T11:14:00.276960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343, nnz=2315598])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c32c50-c71d-4c81-b4e6-8e1e13d7954c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63587477-a332-459a-be96-dcea8781fd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9a422-f6d3-437e-8524-2a52f04fccd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f9816-c184-4373-bb05-51066409a94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b097e41-84da-438f-be84-0fc253ec0101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34881082-5da7-473b-b7bf-45c494439ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ee6a3-10f9-492e-af49-5e2c456711cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29f11c-d127-4f59-9d68-557974a56182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b974f9-d818-4e50-811b-d49573192d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84e2ef-dd04-4bab-ab8a-b4872b80d415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f32ab78-d622-45dc-b542-208f63b312d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ee18e-d550-4c9f-ab2f-513ffee961d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ab108-95d8-4855-ad2a-fa9cc19159d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05aa4a7-ec31-43e3-914c-c94fdf2308c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c5203-06d7-4cce-b7e2-30580d36c2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bb0f3-658a-47a1-9766-db18c45c5672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d94915-da66-4941-b7e6-ac4e2b48bd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d0fc3-147d-4184-8874-71e1ec37a031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965cafd-1746-4849-96cf-9797a8250b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b3424-4a6d-446b-aee1-d63ec5e14cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac120f1-cb45-4167-b43a-b8f65d9063f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e792286-7a0d-44aa-a61e-62080f063560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ca514-351a-4953-90d3-f3ddce13fe04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbf796-5374-422a-8e3b-03427833e150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
